# Microservice 2 : PrÃ©traitement des DonnÃ©es Capteurs

## ğŸ¯ RÃ´le

Le microservice de prÃ©traitement nettoie, normalise et enrichit les **donnÃ©es capteurs IoT** :
- Nettoyage des donnÃ©es
- Normalisation
- DÃ©tection d'anomalies
- Calcul de moyennes mobiles

> âš ï¸ **Note** : Le traitement des images UAV est maintenant gÃ©rÃ© par **MS3 - VisionPlante**

## ğŸ“¥ EntrÃ©es

**Source** : Kafka Topic `sensor-data`
- **Format** : JSON
- **Provenance** : MS1 (Ingestion Capteurs)
- **FrÃ©quence** : Temps rÃ©el (push automatique)

**Exemple de message reÃ§u** :
```json
{
  "sensor_type": "Temperature",
  "timestamp": "2025-12-02T10:30:00Z",
  "data_index": 42,
  "measurements": {
    "Temperature (Â°C)": 25.3
  }
}
```

## âš™ï¸ Traitement

### Pipeline Capteurs IoT

1. **Validation** : VÃ©rification de la structure des donnÃ©es
2. **Extraction** : RÃ©cupÃ©ration de la valeur principale
3. **DÃ©tection d'anomalies** :
   - VÃ©rification des plages de valeurs attendues
   - Calcul du Z-score (si historique suffisant)
   - Seuil : Z-score > 3.0 = anomalie
4. **Nettoyage** :
   - Remplacement des anomalies par la moyenne mobile
   - Gestion des valeurs manquantes
5. **Normalisation** :
   - Min-Max scaling [0, 1]
   - BasÃ© sur les plages dÃ©finies par type de capteur
6. **Features** :
   - Calcul de moyenne mobile (fenÃªtre de 5 mesures)
7. **Score de qualitÃ©** :
   - 1.0 = excellente qualitÃ©
   - PÃ©nalitÃ©s pour anomalies et donnÃ©es manquantes

### Plages de valeurs normales :

| Capteur | Min | Max |
|---------|-----|-----|
| Temperature | -10Â°C | 50Â°C |
| Environment Humidity | 0% | 100% |
| Soil Moisture | 0% | 100% |
| Soil pH | 0 | 14 |
| Light Intensity | 0 lux | 100000 lux |

## ğŸ“¤ Sorties

### 1. TimescaleDB : Table `sensor_data_processed`

**Structure** :
```sql
CREATE TABLE sensor_data_processed (
    id SERIAL PRIMARY KEY,
    sensor_type VARCHAR(100),
    timestamp TIMESTAMPTZ,
    raw_value FLOAT,              -- Valeur brute originale
    clean_value FLOAT,            -- Valeur nettoyÃ©e
    normalized_value FLOAT,       -- Valeur normalisÃ©e [0-1]
    moving_average FLOAT,         -- Moyenne mobile
    quality_score FLOAT,          -- Score de qualitÃ© [0-1]
    is_anomaly BOOLEAN,           -- Anomalie dÃ©tectÃ©e ?
    missing_data_filled BOOLEAN,  -- DonnÃ©e manquante remplie ?
    processing_timestamp TIMESTAMPTZ,
    created_at TIMESTAMPTZ
);
```

**Pourquoi TimescaleDB ?**
- âœ… Stockage permanent (historique illimitÃ©)
- âœ… RequÃªtes SQL complexes et analytics
- âœ… Indexation automatique sur timestamp

### 2. Kafka Topic : `sensor-data-processed`

**Format de message publiÃ©** :
```json
{
  "sensor_type": "Temperature",
  "timestamp": "2025-12-02T10:30:00Z",
  "raw_value": 25.3,
  "clean_value": 25.3,
  "normalized_value": 0.5883,
  "moving_average": 25.45,
  "quality_score": 1.0,
  "is_anomaly": false,
  "missing_data_filled": false,
  "processing_timestamp": "2025-12-02T10:30:01Z"
}
```

**Pourquoi Kafka ?**
- âœ… Notification temps rÃ©el aux services suivants
- âœ… Architecture dÃ©couplÃ©e (event-driven)
- âœ… ScalabilitÃ© horizontale

**Consommateurs** :
- MS3 : VisionPlante (corrÃ©lation avec images)
- MS4 : PrÃ©diction (modÃ¨les ML)
- MS5 : Alertes (dÃ©tection seuils)
- MS6 : Dashboard (visualisation temps rÃ©el)

## ğŸš€ DÃ©marrage

### Via Docker Compose (recommandÃ©)

```bash
# DÃ©marrer tous les services
docker compose up -d

# Voir les logs du prÃ©traitement
docker compose logs -f preprocessing

# ArrÃªter les services
docker compose down
```

### En dÃ©veloppement local

```bash
cd 2-Pretraitement

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement
export KAFKA_BOOTSTRAP_SERVERS=localhost:9092
export KAFKA_INPUT_TOPIC=sensor-data
export KAFKA_OUTPUT_TOPIC=sensor-data-processed
export DB_HOST=localhost

# Lancer le service
python preprocessing.py
```

## ğŸ“Š Configuration

Variables d'environnement :

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `KAFKA_BOOTSTRAP_SERVERS` | Adresse Kafka | `localhost:9092` |
| `KAFKA_INPUT_TOPIC` | Topic d'entrÃ©e | `sensor-data` |
| `KAFKA_OUTPUT_TOPIC` | Topic de sortie | `sensor-data-processed` |
| `KAFKA_GROUP_ID` | Groupe consumer | `preprocessing-group` |
| `DB_HOST` | HÃ´te TimescaleDB | `localhost` |
| `DB_PORT` | Port TimescaleDB | `5432` |
| `DB_NAME` | Nom de la base | `agrotrace` |
| `DB_USER` | Utilisateur DB | `agrotrace_user` |
| `DB_PASSWORD` | Mot de passe DB | `agrotrace_pass` |
| `ANOMALY_THRESHOLD` | Seuil Z-score | `3.0` |
| `MOVING_AVERAGE_WINDOW` | FenÃªtre moyenne | `5` |

## ğŸ“ˆ Statistiques

Le service affiche des statistiques toutes les 30 secondes :

```
==============================================================
  STATISTIQUES - 2025-12-02 10:30:00
==============================================================
  Messages reÃ§us:     1000
  Messages traitÃ©s:   985
  Anomalies dÃ©tectÃ©es: 15
  Erreurs:            15
  Taux de succÃ¨s:     98.50%
--------------------------------------------------------------
```

## ğŸ” Exemples de requÃªtes

### RequÃªtes SQL sur TimescaleDB

```sql
-- DonnÃ©es des derniÃ¨res 24h
SELECT * FROM sensor_data_processed
WHERE timestamp > NOW() - INTERVAL '24 hours'
ORDER BY timestamp DESC;

-- Moyenne par type de capteur (derniÃ¨re heure)
SELECT 
    sensor_type,
    AVG(normalized_value) as avg_norm,
    AVG(quality_score) as avg_quality,
    COUNT(*) as count
FROM sensor_data_processed
WHERE timestamp > NOW() - INTERVAL '1 hour'
GROUP BY sensor_type;

-- Anomalies dÃ©tectÃ©es
SELECT 
    sensor_type,
    timestamp,
    raw_value,
    clean_value
FROM sensor_data_processed
WHERE is_anomaly = true
ORDER BY timestamp DESC
LIMIT 100;

-- Ã‰volution de la tempÃ©rature (avec moyennes mobiles)
SELECT 
    time_bucket('5 minutes', timestamp) AS bucket,
    sensor_type,
    AVG(clean_value) as avg_value,
    AVG(moving_average) as avg_moving
FROM sensor_data_processed
WHERE sensor_type = 'Temperature'
  AND timestamp > NOW() - INTERVAL '2 hours'
GROUP BY bucket, sensor_type
ORDER BY bucket DESC;
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MS1: Ingestion     â”‚
â”‚  Capteurs           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Kafka: sensor-data (temps rÃ©el)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MS2: PrÃ©traitement â”‚
â”‚                     â”‚
â”‚  Pipeline:          â”‚
â”‚  1. Validation      â”‚
â”‚  2. Extraction      â”‚
â”‚  3. DÃ©tection       â”‚
â”‚     anomalies       â”‚
â”‚  4. Nettoyage       â”‚
â”‚  5. Normalisation   â”‚
â”‚  6. Features        â”‚
â”‚  7. QualitÃ©         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚
    â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚TimescaleDB â”‚  â”‚ Kafka:               â”‚
â”‚.processed  â”‚  â”‚ sensor-data-processedâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Services suivants:  â”‚
                 â”‚ - VisionPlante      â”‚
                 â”‚ - PrÃ©diction        â”‚
                 â”‚ - Alertes           â”‚
                 â”‚ - Dashboard         â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Tests

```bash
# VÃ©rifier que le service reÃ§oit des donnÃ©es
docker compose logs preprocessing | grep "Messages reÃ§us"

# VÃ©rifier les anomalies dÃ©tectÃ©es
docker compose logs preprocessing | grep "Anomalies dÃ©tectÃ©es"

# Consulter les donnÃ©es dans TimescaleDB
docker compose exec timescaledb psql -U agrotrace_user -d agrotrace -c \
  "SELECT COUNT(*) FROM sensor_data_processed;"

# VÃ©rifier les topics Kafka
docker compose exec kafka-broker kafka-topics.sh --list \
  --bootstrap-server localhost:9092
```

## ğŸ“ Notes techniques

### Pourquoi lire depuis Kafka (et pas TimescaleDB) ?

1. **Temps rÃ©el** : Push automatique, latence < 1s
2. **Event-driven** : Architecture dÃ©couplÃ©e
3. **ScalabilitÃ©** : Consumer groups pour parallÃ©lisation

### Pourquoi Ã©crire dans les DEUX (TimescaleDB + Kafka) ?

1. **Kafka** : Notification temps rÃ©el aux services
2. **TimescaleDB** : Persistence long terme + analytics

### Algorithmes de prÃ©traitement

- **DÃ©tection anomalies** : Z-score + plages de valeurs
- **Nettoyage** : Interpolation par moyenne mobile
- **Normalisation** : Min-Max scaling
- **Features** : Moyenne mobile sur fenÃªtre glissante

## ğŸ”œ Ã‰volutions futures

- [ ] Interpolation avancÃ©e (LSTM)
- [ ] DÃ©tection d'anomalies contextuelles
- [ ] Calcul d'indices supplÃ©mentaires (EVI, SAVI)
- [ ] API REST pour requÃªtes ad-hoc
- [ ] Support formats images supplÃ©mentaires (JPEG2000)
- [ ] Traitement multi-spectral avancÃ©
